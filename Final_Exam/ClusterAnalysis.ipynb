{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b706955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from meteostat import Point, Daily\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e39682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "   Order Date  Customer Name         State         Category Sub-Category  \\\n",
      "0  03-01-2014  Darren Powers         Texas  Office Supplies        Paper   \n",
      "1  04-01-2014  Phillina Ober      Illinois  Office Supplies       Labels   \n",
      "2  04-01-2014  Phillina Ober      Illinois  Office Supplies      Storage   \n",
      "3  04-01-2014  Phillina Ober      Illinois  Office Supplies      Binders   \n",
      "4  05-01-2014     Mick Brown  Pennsylvania  Office Supplies          Art   \n",
      "\n",
      "                                        Product Name   Sales  Quantity  Profit  \n",
      "0  Message Book, Wirebound, Four 5 1/2\" X 4\" Form...   16.45         2    5.55  \n",
      "1                                          Avery 508   11.78         3    4.27  \n",
      "2                      SAFCO Boltless Steel Shelving  272.74         3  -64.77  \n",
      "3         GBC Standard Plastic Binding Systems Combs    3.54         2   -5.49  \n",
      "4  Avery Hi-Liter EverBold Pen Style Fluorescent ...   19.54         3    4.88  \n"
     ]
    }
   ],
   "source": [
    "# --- Load Dataset ---\n",
    "# Import the dataset uploaded to the repo\n",
    "url = \"https://raw.githubusercontent.com/MaharLeika18/Data-Mining---Python/refs/heads/main/Final_Exam/Raw%20Data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c33bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2014-01-03 to 2017-12-30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Coords</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>Darren Powers</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Paper</td>\n",
       "      <td>Message Book, Wirebound, Four 5 1/2\" X 4\" Form...</td>\n",
       "      <td>16.45</td>\n",
       "      <td>2</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1</td>\n",
       "      <td>(31.054487, -97.563461)</td>\n",
       "      <td>31.054487</td>\n",
       "      <td>-97.563461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>Phillina Ober</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Avery 508</td>\n",
       "      <td>11.78</td>\n",
       "      <td>3</td>\n",
       "      <td>4.27</td>\n",
       "      <td>2</td>\n",
       "      <td>(40.349457, -88.986137)</td>\n",
       "      <td>40.349457</td>\n",
       "      <td>-88.986137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>Phillina Ober</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>SAFCO Boltless Steel Shelving</td>\n",
       "      <td>272.74</td>\n",
       "      <td>3</td>\n",
       "      <td>-64.77</td>\n",
       "      <td>3</td>\n",
       "      <td>(40.349457, -88.986137)</td>\n",
       "      <td>40.349457</td>\n",
       "      <td>-88.986137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>Phillina Ober</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>GBC Standard Plastic Binding Systems Combs</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>4</td>\n",
       "      <td>(40.349457, -88.986137)</td>\n",
       "      <td>40.349457</td>\n",
       "      <td>-88.986137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>Mick Brown</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Art</td>\n",
       "      <td>Avery Hi-Liter EverBold Pen Style Fluorescent ...</td>\n",
       "      <td>19.54</td>\n",
       "      <td>3</td>\n",
       "      <td>4.88</td>\n",
       "      <td>5</td>\n",
       "      <td>(40.590752, -77.209755)</td>\n",
       "      <td>40.590752</td>\n",
       "      <td>-77.209755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order Date  Customer Name         State         Category Sub-Category  \\\n",
       "0 2014-01-03  Darren Powers         Texas  Office Supplies        Paper   \n",
       "1 2014-01-04  Phillina Ober      Illinois  Office Supplies       Labels   \n",
       "2 2014-01-04  Phillina Ober      Illinois  Office Supplies      Storage   \n",
       "3 2014-01-04  Phillina Ober      Illinois  Office Supplies      Binders   \n",
       "4 2014-01-05     Mick Brown  Pennsylvania  Office Supplies          Art   \n",
       "\n",
       "                                        Product Name   Sales  Quantity  \\\n",
       "0  Message Book, Wirebound, Four 5 1/2\" X 4\" Form...   16.45         2   \n",
       "1                                          Avery 508   11.78         3   \n",
       "2                      SAFCO Boltless Steel Shelving  272.74         3   \n",
       "3         GBC Standard Plastic Binding Systems Combs    3.54         2   \n",
       "4  Avery Hi-Liter EverBold Pen Style Fluorescent ...   19.54         3   \n",
       "\n",
       "   Profit  Transaction ID                   Coords   Latitude  Longitude  \n",
       "0    5.55               1  (31.054487, -97.563461)  31.054487 -97.563461  \n",
       "1    4.27               2  (40.349457, -88.986137)  40.349457 -88.986137  \n",
       "2  -64.77               3  (40.349457, -88.986137)  40.349457 -88.986137  \n",
       "3   -5.49               4  (40.349457, -88.986137)  40.349457 -88.986137  \n",
       "4    4.88               5  (40.590752, -77.209755)  40.590752 -77.209755  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Data Preprocessing ---\n",
    "# Create id column\n",
    "data['Transaction ID'] = data.index + 1\n",
    "\n",
    "# Convert dates to datetime\n",
    "data['Order Date'] = pd.to_datetime(data['Order Date'], format='%d-%m-%Y')\n",
    "start = data['Order Date'].min()\n",
    "end = data['Order Date'].max()\n",
    "print(f\"Date range: {start.date()} to {end.date()}\")\n",
    "\n",
    "# Convert states to coordinates\n",
    "# LOUE NOTE: FULL DISCLAIMER I had chatgpt gen these coords cuz no way am i doing this manually.\n",
    "# so if the cords are innacurate im sorry\n",
    "# or well chatgpt should be sorry but unlike caine its not sentient\n",
    "\n",
    "state_coords = {\n",
    "    \"Alabama\": (32.806671, -86.791130),\n",
    "    \"Alaska\": (61.370716, -152.404419),\n",
    "    \"Arizona\": (33.729759, -111.431221),\n",
    "    \"Arkansas\": (34.969704, -92.373123),\n",
    "    \"California\": (36.116203, -119.681564),\n",
    "    \"Colorado\": (39.059811, -105.311104),\n",
    "    \"Connecticut\": (41.597782, -72.755371),\n",
    "    \"Delaware\": (39.318523, -75.507141),\n",
    "    \"Florida\": (27.766279, -81.686783),\n",
    "    \"Georgia\": (33.040619, -83.643074),\n",
    "    \"Hawaii\": (21.094318, -157.498337),\n",
    "    \"Idaho\": (44.240459, -114.478828),\n",
    "    \"Illinois\": (40.349457, -88.986137),\n",
    "    \"Indiana\": (39.849426, -86.258278),\n",
    "    \"Iowa\": (42.011539, -93.210526),\n",
    "    \"Kansas\": (38.526600, -96.726486),\n",
    "    \"Kentucky\": (37.668140, -84.670067),\n",
    "    \"Louisiana\": (31.169546, -91.867805),\n",
    "    \"Maine\": (44.693947, -69.381927),\n",
    "    \"Maryland\": (39.063946, -76.802101),\n",
    "    \"Massachusetts\": (42.230171, -71.530106),\n",
    "    \"Michigan\": (43.326618, -84.536095),\n",
    "    \"Minnesota\": (45.694454, -93.900192),\n",
    "    \"Mississippi\": (32.741646, -89.678696),\n",
    "    \"Missouri\": (38.456085, -92.288368),\n",
    "    \"Montana\": (46.921925, -110.454353),\n",
    "    \"Nebraska\": (41.125370, -98.268082),\n",
    "    \"Nevada\": (38.313515, -117.055374),\n",
    "    \"New Hampshire\": (43.452492, -71.563896),\n",
    "    \"New Jersey\": (40.298904, -74.521011),\n",
    "    \"New Mexico\": (34.840515, -106.248482),\n",
    "    \"New York\": (42.165726, -74.948051),\n",
    "    \"North Carolina\": (35.630066, -79.806419),\n",
    "    \"North Dakota\": (47.528912, -99.784012),\n",
    "    \"Ohio\": (40.388783, -82.764915),\n",
    "    \"Oklahoma\": (35.565342, -96.928917),\n",
    "    \"Oregon\": (44.572021, -122.070938),\n",
    "    \"Pennsylvania\": (40.590752, -77.209755),\n",
    "    \"Rhode Island\": (41.680893, -71.511780),\n",
    "    \"South Carolina\": (33.856892, -80.945007),\n",
    "    \"South Dakota\": (44.299782, -99.438828),\n",
    "    \"Tennessee\": (35.747845, -86.692345),\n",
    "    \"Texas\": (31.054487, -97.563461),\n",
    "    \"Utah\": (40.150032, -111.862434),\n",
    "    \"Vermont\": (44.045876, -72.710686),\n",
    "    \"Virginia\": (37.769337, -78.169968),\n",
    "    \"Washington\": (47.400902, -121.490494),\n",
    "    \"West Virginia\": (38.491226, -80.954456),\n",
    "    \"Wisconsin\": (44.268543, -89.616508),\n",
    "    \"Wyoming\": (42.755966, -107.302490)\n",
    "}\n",
    "\n",
    "data['Coords'] = data['State'].map(state_coords)\n",
    "data[['Latitude', 'Longitude']] = pd.DataFrame(data['Coords'].tolist(), index=data.index)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dcc465f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load daily/2015/6X8YG.csv.gz from https://data.meteostat.net/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m location = Point(lat, lon)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     w = \u001b[43mDaily\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m.fetch()\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m w.empty:\n\u001b[32m     11\u001b[39m         w = w.reset_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Data-Mining---Python/.venv/lib/python3.13/site-packages/meteostat/interface/daily.py:111\u001b[39m, in \u001b[36mDaily.__init__\u001b[39m\u001b[34m(self, loc, start, end, model, flags)\u001b[39m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mself\u001b[39m._annual_steps = [\n\u001b[32m    108\u001b[39m         start.year + i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end.year - start.year + \u001b[32m1\u001b[39m)\n\u001b[32m    109\u001b[39m     ]\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Initialize time series\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Data-Mining---Python/.venv/lib/python3.13/site-packages/meteostat/interface/timeseries.py:176\u001b[39m, in \u001b[36mTimeSeries._init_time_series\u001b[39m\u001b[34m(self, loc, start, end, model, flags)\u001b[39m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28mself\u001b[39m._stations = loc.index\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, Point):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     stations = \u001b[43mloc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_stations\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdaily\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m     \u001b[38;5;28mself\u001b[39m._stations = stations.index\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Data-Mining---Python/.venv/lib/python3.13/site-packages/meteostat/interface/point.py:79\u001b[39m, in \u001b[36mPoint.get_stations\u001b[39m\u001b[34m(self, freq, start, end, model)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Guess altitude if not set\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28mself\u001b[39m._alt = \u001b[43mstations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.head(\u001b[38;5;28mself\u001b[39m.max_count)[\u001b[33m\"\u001b[39m\u001b[33melevation\u001b[39m\u001b[33m\"\u001b[39m].mean()\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Captue unfiltered weather stations\u001b[39;00m\n\u001b[32m     82\u001b[39m unfiltered = stations.fetch()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Data-Mining---Python/.venv/lib/python3.13/site-packages/meteostat/interface/stations.py:232\u001b[39m, in \u001b[36mStations.fetch\u001b[39m\u001b[34m(self, limit, sample)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[33;03m    Return number of weather stations in current selection\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._data.index)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, limit: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m, sample: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> pd.DataFrame:\n\u001b[32m    233\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[33;03m    Fetch all weather stations or a (sampled) subset\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    237\u001b[39m     \u001b[38;5;66;03m# Copy DataFrame\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Get historical weather data for each state\n",
    "weather_records = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    lat, lon = row['Latitude'], row['Longitude']\n",
    "    location = Point(lat, lon)\n",
    "\n",
    "    try:\n",
    "        w = Daily(location, start, end).fetch()\n",
    "        if not w.empty:\n",
    "            w = w.reset_index()\n",
    "            w['Latitude'] = lat\n",
    "            w['Longitude'] = lon\n",
    "            weather_records.append(w)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch for {lat}, {lon} on {start}, {end}: {e}\")\n",
    "        continue\n",
    "\n",
    "weather_data = pd.concat(weather_records, ignore_index=True)\n",
    "\n",
    "print(f\"Shape: {weather_data.shape}\")\n",
    "display(weather_data[['Order Date', 'tavg', 'prcp', 'wspd']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88601d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>wpgt</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tavg, tmin, tmax, prcp, snow, wdir, wspd, wpgt, pres, tsun]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get historical weather data for each state (DELETE WHEN ABOVE CELL WORKS)\n",
    "location = Point(14.5995, 120.9842, 70)\n",
    "\n",
    "weather_data = Daily(location, start, end)\n",
    "weather_data = weather_data.fetch()\n",
    "\n",
    "weather_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7664ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add description to the data\n",
    "def get_weather_description(row):\n",
    "    temp = row['tavg']  # average temperature\n",
    "    precip = row['prcp']  # precipitation\n",
    "    \n",
    "    if pd.isna(temp) or pd.isna(precip):\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    if precip > 10: \n",
    "        return \"Heavy Rain\"\n",
    "    elif precip > 5:\n",
    "        return \"Rainy\"\n",
    "    elif precip > 1:\n",
    "        return \"Light Rain\" \n",
    "    elif temp > 29:\n",
    "        return \"Sunny\"\n",
    "    elif temp > 27:\n",
    "        return \"Partly Cloudy\"\n",
    "    else: \n",
    "        return \"Warm and Humid\"\n",
    "\n",
    "# Apply weather descriptions\n",
    "weather_data['weather'] = weather_data.apply(get_weather_description, axis=1)\n",
    "\n",
    "print(\"Weather text descriptions:\")\n",
    "print(weather_data['weather'].value_counts())\n",
    "weather_data[['tavg', 'prcp', 'weather']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weather_data_reset for merging\n",
    "weather_data_reset = weather_data.reset_index()\n",
    "weather_data_reset.rename(columns={'time': 'Order Date'}, inplace=True)\n",
    "\n",
    "print(f\"Shape: {weather_data_reset.shape}\")\n",
    "display(weather_data_reset[['Order Date', 'weather']].head())\n",
    "\n",
    "display(weather_data_reset)\n",
    "\n",
    "# Merge \n",
    "data_with_weather = pd.merge(data, weather_data_reset[['Order Date','weather','tavg','prcp','wspd']], on='Order Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ae0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "data_with_weather.to_csv('retail_data_with_weather.csv', index=False)\n",
    "display(data_with_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7a9dc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessories</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>Art</th>\n",
       "      <th>Binders</th>\n",
       "      <th>Bookcases</th>\n",
       "      <th>Chairs</th>\n",
       "      <th>Copiers</th>\n",
       "      <th>Envelopes</th>\n",
       "      <th>Fasteners</th>\n",
       "      <th>Furnishings</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Machines</th>\n",
       "      <th>Paper</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Storage</th>\n",
       "      <th>Supplies</th>\n",
       "      <th>Tables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accessories  Appliances    Art  Binders  Bookcases  Chairs  Copiers  \\\n",
       "0        False       False  False    False      False   False    False   \n",
       "1        False       False  False    False      False   False    False   \n",
       "2        False       False  False    False      False   False    False   \n",
       "3        False       False  False     True      False   False    False   \n",
       "4        False       False   True    False      False   False    False   \n",
       "\n",
       "   Envelopes  Fasteners  Furnishings  Labels  Machines  Paper  Phones  \\\n",
       "0      False      False        False   False     False   True   False   \n",
       "1      False      False        False    True     False  False   False   \n",
       "2      False      False        False   False     False  False   False   \n",
       "3      False      False        False   False     False  False   False   \n",
       "4      False      False        False   False     False  False   False   \n",
       "\n",
       "   Storage  Supplies  Tables  \n",
       "0    False     False   False  \n",
       "1    False     False   False  \n",
       "2     True     False   False  \n",
       "3    False     False   False  \n",
       "4    False     False   False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- One-hot encode categorical data ---\n",
    "# LOUE NOTE: Do this immediately before tha association analysis\n",
    "# Or merge df with data because df contains only the one-hot encoded data\n",
    "\n",
    "transactions = data.groupby('Transaction ID')['Category'].apply(list).values.tolist()\n",
    "transactions = data.groupby('Transaction ID')['Sub-Category'].apply(list).values.tolist()\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
